import torch
import math
import collections
from torch import nn
import matplotlib.pyplot as plt



DATA_HUB = dict()
DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'

DATA_HUB['fra-eng'] = (DATA_URL + 'fra-eng.zip', '94646ad1522d915e7b0f9296181140edcf86a4f5')

import numpy as np
import torch


from torch import nn
from torch.nn import functional as F
from torch.utils import data




#################   WARNING   ################
# The below part is generated automatically through:
#    d2lbook build lib
# Don't edit it directly

import collections
import hashlib
import math
import os

import tarfile
import time
import zipfile

import requests

from matplotlib import pyplot as plt



import numpy as np
import torch


from torch import nn
from torch.utils import data
import time


# ç¼–ç å™¨æ¥å£
class Encoder(nn.Module):
    """ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºæœ¬ç¼–ç å™¨æ¥å£"""
    def __init__(self, **kwargs):
        super(Encoder, self).__init__(**kwargs)

    def forward(self, inputs, *args):
        raise NotImplementedError

# ç¼–ç å™¨æ¥å£
class Decoder(nn.Module):
    """ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºæœ¬è§£ç å™¨æ¥å£"""
    def __init__(self, **kwargs):
        super(Decoder, self).__init__(**kwargs)

    def init_state(self, state, *args):
        raise NotImplementedError

    def forward(self, inputs, state):
        raise NotImplementedError

# ç¼–ç å™¨-è§£ç å™¨
class EncoderDecoder(nn.Module):
    # å®šä¹‰ç½‘ç»œ
    def __init__(self, encoder, decoder, **kwargs):
        super(EncoderDecoder, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
    
    # å®šä¹‰å‰å‘ä¼ æ’­
    def forward(self, src_inputs, tgt_inputs, *args):
        # ç¼–ç 
        states, enc_state = self.encoder(src_inputs, *args)
        # è§£ç 
        dec_state = self.decoder.init_state(enc_state, *args)
        return self.decoder(tgt_inputs, dec_state)

# Seq2Seqç¼–ç å™¨ï¼šè¾“å…¥æºå¥å­
class Seq2SeqEncoder(Encoder):
    # å®šä¹‰ç½‘ç»œ
    def __init__(self, src_vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):
        super(Seq2SeqEncoder, self).__init__(**kwargs)
        # åµŒå…¥å±‚(D,E)
        self.embedding = nn.Embedding(
            num_embeddings=src_vocab_size, 
            embedding_dim=embed_size
        )
        # å¾ªç¯ç¥ç»ç½‘ç»œå±‚(E,H,L)
        self.rnn = nn.GRU(
            input_size=embed_size, 
            hidden_size=num_hiddens, 
            num_layers=num_layers, 
            dropout=dropout
        )
        # æ²¡æœ‰è¾“å‡ºå±‚
    
    # å®šä¹‰å‰å‘ä¼ æ’­
    # inputs(B,T)
    # states(T,B,H)
    # state(L,B,H)
    def forward(self, inputs, *args):
        # inputs(B,T)->(B,T,E)
        inputs = self.embedding(inputs)
        # inputs(T,B,E)
        inputs = inputs.permute(1, 0, 2)
        # states(T,B,H),state(L,B,H)
        states, state = self.rnn(inputs)
        # states:åŒ…å«æ¯ä¸ªæ—¶é—´æ­¥æœ€åä¸€å±‚çš„ä¿¡æ¯
        # state:åŒ…å«æœ€åä¸€ä¸ªæ—¶é—´æ­¥æ¯ä¸€å±‚çš„ä¿¡æ¯
        return states, state
    
# Seq2Seqè§£ç å™¨ï¼šè¾“å…¥ç›®æ ‡å¥å­çš„è¯å…ƒï¼Œé¢„æµ‹ç›®æ ‡å¥å­çš„ä¸‹ä¸€ä¸ªè¯å…ƒ
class Seq2SeqDecoder(Decoder):
    # å®šä¹‰ç½‘ç»œ
    def __init__(self, tgt_vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):
        super(Seq2SeqDecoder, self).__init__(**kwargs)
        # åµŒå…¥å±‚(D,E)
        self.embedding = nn.Embedding(
            num_embeddings=tgt_vocab_size, 
            embedding_dim=embed_size
        )
        # å¾ªç¯ç¥ç»ç½‘ç»œå±‚(E+H,H,L)
        self.rnn = nn.GRU(
            input_size=embed_size + num_hiddens, 
            hidden_size=num_hiddens, 
            num_layers=num_layers, 
            dropout=dropout
        )
        # è¾“å‡ºå±‚(H,D)
        self.dense = nn.Linear(
            in_features=num_hiddens, 
            out_features=tgt_vocab_size
        )


    # åˆå§‹åŒ–è§£ç å™¨çŠ¶æ€
    def init_state(self, enc_state, *args):
        return enc_state # (L,B,H)

    # å®šä¹‰å‰å‘ä¼ æ’­
    # inputs(B,T)
    # output(B,T,D)
    # state(L,B,H)
    def forward(self, inputs, state):
        # inputs(B,T) -> (B,T,E)
        inputs = self.embedding(inputs)
        # inputs(T,B,E)
        inputs = inputs.permute(1, 0, 2)
        # inputs(T,B,E)
        # state(L,B,H),state[-1](B,H)
        # context(T,B,H)
        context = state[-1].repeat(inputs.shape[0], 1, 1)
        # inputs_and_context(T,B,E+H)
        inputs_and_context = torch.cat((inputs, context), 2)
        # states(T,B,H)
        # state(L,B,H)
        states, state = self.rnn(inputs_and_context, state)
        # è¾“å‡ºå±‚ï¼Œå°†éšè—çŠ¶æ€æ˜ å°„åˆ°è¾“å‡ºç©ºé—´
        # output(T,B,H) -> (T,B,D)
        output = self.dense(states)
        # output(B,T,D)
        output = output.permute(1, 0, 2)
        return output, state
        # åœ¨è®­ç»ƒé˜¶æ®µï¼Œoutput æ¥ä¸‹æ¥é€å…¥ loss æŸå¤±å‡½æ•°æ›´æ–°æ¢¯åº¦
        # åœ¨é¢„æµ‹é˜¶æ®µï¼Œoutput æ¥ä¸‹æ¥é€å…¥ argmax å‡½æ•°è·å–é¢„æµ‹ç»“æœ


# å®šä¹‰è®­ç»ƒå‡½æ•°
def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):
    # åˆå§‹åŒ–æ¨¡å‹å‚æ•°
    def xavier_init_weights(m):
        if isinstance(m, nn.Linear):
            nn.init.xavier_uniform_(m.weight)  # åˆå§‹åŒ–çº¿æ€§å±‚çš„æƒé‡ä¸ºå‡åŒ€åˆ†å¸ƒ
        elif isinstance(m, nn.GRU):
            for name, param in m.named_parameters():
                if "weight" in name:
                    nn.init.xavier_uniform_(param)  # åˆå§‹åŒ–å¾ªç¯ç¥ç»ç½‘ç»œå±‚çš„æƒé‡ä¸ºå‡åŒ€åˆ†å¸ƒ
    # åº”ç”¨åˆå§‹åŒ–å‡½æ•°
    net.apply(xavier_init_weights)
    net.to(device)
    net.train()
    # å®šä¹‰ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    loss = MaskedSoftmaxCELoss(ignore_index=tgt_vocab['<pad>']) # äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œç”¨äºå¤šåˆ†ç±»é—®é¢˜

    # åˆå§‹åŒ–ç»˜å›¾
    fig, ax, line, x_list, y_list = init_plot(lr)

    # è®­ç»ƒ
    for epoch in range(num_epochs):
        timer = Timer()
        # å®šä¹‰ç´¯åŠ å™¨ï¼Œç”¨äºè®°å½•æ¯ä¸ªepochçš„æŸå¤±æ€»å’Œå’Œè¯å…ƒæ€»æ•°
        metric = Accumulator(2)
        # æŒ‰ç…§æ‰¹æ¬¡è®­ç»ƒï¼Œå¥½å¤„æ˜¯æ¢¯åº¦ä¸‹é™æ›´ç¨³å®š
        for batch in data_iter:
            # æ‹¿å–æ‰¹æ¬¡æ•°æ®
            # src_inputs(B,T)
            # tgt_inputs(B,T)
            # tgt_valid_len(B)
            src_inputs, _, tgt_inputs, tgt_valid_len = batch
            # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
            src_inputs = src_inputs.to(device)
            tgt_inputs = tgt_inputs.to(device)
            tgt_valid_len = tgt_valid_len.to(device)
   
            # bos(B,1)
            bos = torch.tensor([tgt_vocab['<bos>']] * tgt_inputs.shape[0], device=device).reshape(-1, 1) # ç›®æ ‡è¾“å…¥åœ¨è®­ç»ƒé˜¶æ®µéœ€è¦æ·»åŠ <bos>æ ‡è®°
            # tgt_teach(B,1+T-1)->(B,T)
            tgt_teach = torch.cat([bos, tgt_inputs[:, :-1]], 1) # ç›®æ ‡è¾“å…¥åœ¨è®­ç»ƒé˜¶æ®µéœ€è¦å»æ‰æœ€åä¸€ä¸ªè¯å…ƒ            

            # start_time = time.time()
          

            # 1.æ¸…é›¶æ¢¯åº¦
            optimizer.zero_grad()
            # 2.è®­ç»ƒï¼Œæ‰§è¡Œå¼ºåˆ¶æ•™å­¦
            outputs, _ = net(src_inputs, tgt_teach) # outputs(B,T,D)
            # 3.è®¡ç®—æŸå¤±
            l = loss(outputs, tgt_inputs) #å‹ç¼© T,l(B)
            l = l.sum() # å‹ç¼© B,l(1)ï¼Œæ¯ä¸ªæ‰¹æ¬¡çš„æŸå¤±æ±‚å’Œ
            # 4.åå‘ä¼ æ’­(è®¡ç®—æ¢¯åº¦æœ€è€—æ—¶)
            l.backward()
            # 5.æ¢¯åº¦è£å‰ª
            grad_clipping(net, 1)
            # 6.æ›´æ–°å‚æ•°
            optimizer.step()

            # end_time = time.time()
            # print(f"æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡è€—æ—¶: {end_time - start_time:.6f} ç§’")


            # ç´¯åŠ æ‰¹æ¬¡çš„æŸå¤±å’Œè¯å…ƒæ•°é‡
            with torch.no_grad():
                metric.add(l, tgt_valid_len.sum())
        train_loss = metric[0] / metric[1]
        train_speed = metric[1] / timer.stop()
        print(f'epoch {(epoch + 1):3d}/{num_epochs}, loss {train_loss:.3f}, {train_speed:.1f} è¯å…ƒ/ç§’ {str(device)}')



        # æ›´æ–°ç»˜å›¾
        update_plot(epoch+1, train_loss, x_list, y_list, line, ax)


    # å…³é—­ç»˜å›¾
    close_plot()


# åˆå§‹åŒ–ç»˜å›¾
def init_plot(lr):
    plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼
    fig, ax = plt.subplots(figsize=(10, 6))
    x_list = [] # xè½´æ•°æ®
    y_list = [] # yè½´æ•°æ®
    line, = ax.plot(x_list, y_list, 'b-', linewidth=2, label='Perplexity')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('loss')
    ax.set_title(f'RNN Training loss vs Epoch (lr={lr})')
    ax.grid(True)
    ax.legend()
    plt.tight_layout()
    return fig, ax, line, x_list, y_list
    # figæ˜¯ç”»å¸ƒ
    # axæ˜¯åæ ‡ç³»åŒºåŸŸ(axisæ˜¯å¸¦åˆ»åº¦çš„å›¾è¡¨æ¡†)ï¼Œä¸€ä¸ªfig ä¸Šå¯ä»¥æœ‰å¤šä¸ª ax
    # lineæ˜¯çº¿å¯¹è±¡
    # x_listå’Œy_listæ˜¯æ•°æ®åˆ—è¡¨


# æ›´æ–°ç»˜å›¾
def update_plot(x_item, y_item, x_list, y_list, line, ax):
    x_list.append(x_item)
    y_list.append(y_item)
    line.set_xdata(x_list)
    line.set_ydata(y_list)
    ax.set_xlim(0, x_item + 2)  # ç¡®ä¿xè½´èŒƒå›´åŒ…å«å½“å‰epochï¼Œå³è¾¹é¢„ç•™2ä¸ªå•ä½
    ax.set_ylim(0, max(y_list) * 1.1 if y_list else 1)  # é˜²æ­¢ç©ºåˆ—è¡¨æŠ¥é”™ï¼Œyè½´é¢„ç•™10%
    plt.draw()
    plt.pause(0.01)

# å…³é—­ç»˜å›¾
def close_plot():
    plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼->æ¢å¤é»˜è®¤è¡Œä¸º
    plt.show()  # é˜»å¡ï¼Œä¿æŒçª—å£æ‰“å¼€ç›´åˆ°ç”¨æˆ·æ‰‹åŠ¨å…³é—­


# å¸¦é®è”½çš„softmaxäº¤å‰ç†µæŸå¤±å‡½æ•°
class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
    def __init__(self, ignore_index=0, **kwargs):  # é»˜è®¤è®¾ä¸º 0ï¼Œé€‚é…ä½ çš„ padding
        super(MaskedSoftmaxCELoss, self).__init__(
            ignore_index=ignore_index, # å¿½ç•¥ç›®æ ‡ä¸­å€¼ç­‰äº ignore_index çš„ä½ç½®
            reduction='none',  # ä¿æŒé€å…ƒç´ è®¡ç®—
            **kwargs
        )

    def forward(self, input, target):
        # è®¡ç®—é€ä½ç½®æŸå¤±ï¼Œæ— æ•ˆä½ç½®ï¼ˆignore_indexï¼‰æŸå¤±ä¸º 0
        # input éœ€è¦ (B, D, T)ï¼Œtarget æ˜¯ (B, T)
        # input(B,T,D)->(B,D,T)
        unweighted_loss = super().forward(input.permute(0, 2, 1), target)  # (B, T)

        # åˆ›å»ºæœ‰æ•ˆä½ç½®æ©ç ï¼štarget ä¸­ä¸ç­‰äº ignore_index çš„ä½ç½®ä¸º 1
        # mask: (B, T)
        mask = (target != self.ignore_index).float()

        # å¯¹æ¯ä¸ªæ ·æœ¬ï¼Œè®¡ç®—æœ‰æ•ˆæŸå¤±æ€»å’Œ
        # loss_sum: (B,)
        loss_sum = (unweighted_loss * mask).sum(dim=1)

        # è·å–æ¯ä¸ªæ ·æœ¬çš„æœ‰æ•ˆ token æ•°é‡ï¼ˆé¿å…é™¤é›¶ï¼‰
        # valid_token_count: (B,)
        valid_token_count = mask.sum(dim=1).clamp(min=1)  # è‡³å°‘ä¸º1ï¼Œé˜²æ­¢é™¤é›¶

        # è®¡ç®—æ¯ä¸ªå¥å­çš„å¹³å‡æŸå¤±
        # weighted_loss: (B,)
        weighted_loss = loss_sum / valid_token_count

        return weighted_loss

# å®šä¹‰é¢„æµ‹å‡½æ•°ï¼Œç«¯åˆ°ç«¯é¢„æµ‹
def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False):
    # æºå¥å­å°å†™åŒ–å¹¶åˆ†è¯ï¼Œsource(T,)
    source = src_sentence.lower().split(' ')
    # æºå¥å­è¯å…ƒåŒ–,src_tokens(T,)
    src_tokens = src_vocab[source] + [src_vocab['<eos>']]
    # æºå¥å­æˆªæ–­ã€å¡«å……,src_tokens(T,)
    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])
    # src_inputs(1,T)
    src_inputs = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)
    pred_seq, attention_weight_seq = [], []
    
    # ç¼–ç 
    net.eval()
    # states(T,B,H)=(T,1,H)
    # enc_state(L,B,H)=(1,1,H)
    states, enc_state = net.encoder(src_inputs)

    # è§£ç 
    # dec_state(L,B,H)=(L,1,H)
    dec_state = net.decoder.init_state(enc_state)
    # ç¬¬ä¸€ä¸ªè¾“å…¥æ˜¯<bos>ï¼Œnext_input(1,1)
    next_input = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)

    for _ in range(num_steps):
        # tgt_hat(1,1,D)
        # dec_state(L,B,H)=(L,1,H)
        tgt_hat, dec_state = net.decoder(next_input, dec_state)
        # next_input(1,1)
        next_input = tgt_hat.argmax(dim=2)
        # pred(1,)
        pred = next_input.squeeze(dim=0).type(torch.int32).item()
        # ä¿å­˜æ³¨æ„åŠ›æƒé‡ï¼ˆç¨åè®¨è®ºï¼‰
        if save_attention_weights:
            attention_weight_seq.append(net.decoder.attention_weights)
        # ä¸€æ—¦åºåˆ—<eos>è¯å…ƒè¢«é¢„æµ‹ï¼Œè¾“å‡ºåºåˆ—çš„ç”Ÿæˆå°±å®Œæˆäº†
        if pred == tgt_vocab['<eos>']:
            break
        pred_seq.append(pred) # è¯å…ƒç´¢å¼•åˆ—è¡¨
        outputs = ' '.join(tgt_vocab.to_tokens(pred_seq)) # è¯å…ƒåˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    return outputs, attention_weight_seq

# é¢„æµ‹åºåˆ—çš„è¯„ä¼°-å¸ƒé²ç®—æ³•
def bleu(pred_src, label_src, k):
    # é¢„æµ‹åºåˆ—å’Œæ ‡ç­¾åºåˆ—éƒ½å°å†™åŒ–å¹¶åˆ†è¯
    pred_tokens, label_tokens = pred_src.lower().split(' '), label_src.lower().split(' ')
    len_pred, len_label = len(pred_tokens), len(label_tokens)
    # è®¡ç®—æƒ©ç½šåˆ†æ•°
    score = math.exp(min(0, 1 - len_label / len_pred))
    # è®¡ç®—nå…ƒè¯­æ³•çš„åŒ¹é…ç‡
    for n in range(1, k + 1):
        # ç»Ÿè®¡æ ‡ç­¾åºåˆ—ä¸­nå…ƒè¯­æ³•çš„å‡ºç°æ¬¡æ•°
        num_n_grams = len_label - n + 1 # åˆ†æ¯ï¼šæ ‡ç­¾åºåˆ—ä¸­ nå…ƒè¯­æ³•çš„æ€»æ•°é‡
        label_subs = collections.defaultdict(int) # label_subså­—å…¸
        for i in range(len_label - n + 1):
            label_subs[' '.join(label_tokens[i: i + n])] += 1 # labelå­åºåˆ—å‡ºç°çš„æ¬¡æ•°,å› ä¸º nå…ƒè¯­æ³•å­åºåˆ—æœ‰é‡å¤çš„ï¼Œæ‰€ä»¥è¿™é‡Œè¦å½’ç±»ç´¯åŠ 
        
        # ç»Ÿè®¡predå­åºåˆ—åœ¨labelå­åºåˆ—ä¸­å‡ºç°
        num_matches = 0 # åˆ†å­ï¼špredåºåˆ—ä¸æ ‡ç­¾åºåˆ—ä¸­åŒ¹é…çš„ nå…ƒè¯­æ³•çš„æ•°é‡
        for i in range(len_pred - n + 1):
            if label_subs[' '.join(pred_tokens[i: i + n])] > 0: # predå­åºåˆ—åœ¨labelå­åºåˆ—ä¸­å‡ºç°
                num_matches += 1 # åŒ¹é…æ•°åŠ 1
                label_subs[' '.join(pred_tokens[i: i + n])] -= 1 # åŒ¹é…çš„labelå­åºåˆ—æ¬¡æ•°å‡1
        # è®¡ç®—nå…ƒè¯­æ³•çš„åŒ¹é…ç‡
        p_n = num_matches / num_n_grams
        # è®¡ç®—nå…ƒè¯­æ³•çš„BLEUåˆ†æ•°
        score *= math.pow(p_n, math.pow(0.5, n))
    return score

def main():
    # 1.è¶…å‚æ•°
    embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1
    batch_size, num_steps = 64, 10
    lr, num_epochs, device = 0.005, 300, try_gpu()
    print(device)

    # 2.åŠ è½½æ•°æ®é›†
    train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps, device)
    
    # 3.åˆå§‹åŒ–æ¨¡å‹
    encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)
    decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)
    net = EncoderDecoder(encoder, decoder)

    # 4.è®­ç»ƒæ¨¡å‹
    train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)

    # 5.é¢„æµ‹
    engs = ['go .', "i lost .", 'he\'s calm .', 'i\'m home .']
    fras = ['va !', 'j\'ai perdu .', 'il est calme .', 'je suis chez moi .']
    print('----------------------------------------------------------------')
    for eng, fra in zip(engs, fras):
        translation, attention_weight_seq = predict_seq2seq(net, eng, src_vocab, tgt_vocab, num_steps, device)
        print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')







def try_gpu(i=0):
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:{i}')
    elif torch.backends.mps.is_available():
        return torch.device('mps')
    return torch.device('cpu')

def count_corpus(tokens):
    """Count token frequencies.

    Defined in :numref:`sec_text_preprocessing`"""
    # Here `tokens` is a 1D list or 2D list
    if len(tokens) == 0 or isinstance(tokens[0], list):
        # Flatten a list of token lists into a list of tokens
        tokens = [token for line in tokens for token in line]
    return collections.Counter(tokens)

class Vocab:
    """Vocabulary for text."""
    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):
        """Defined in :numref:`sec_text_preprocessing`"""
        if tokens is None:
            tokens = []
        if reserved_tokens is None:
            reserved_tokens = []
        # Sort according to frequencies
        counter = count_corpus(tokens)
        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],
                                   reverse=True)
        # The index for the unknown token is 0
        self.idx_to_token = ['<unk>'] + reserved_tokens
        self.token_to_idx = {token: idx
                             for idx, token in enumerate(self.idx_to_token)}
        for token, freq in self._token_freqs:
            if freq < min_freq:
                break
            if token not in self.token_to_idx:
                self.idx_to_token.append(token)
                self.token_to_idx[token] = len(self.idx_to_token) - 1

    def __len__(self):
        return len(self.idx_to_token)

    def __getitem__(self, tokens):
        if not isinstance(tokens, (list, tuple)):
            return self.token_to_idx.get(tokens, self.unk)
        return [self.__getitem__(token) for token in tokens]

    def to_tokens(self, indices):
        if not isinstance(indices, (list, tuple)):
            return self.idx_to_token[indices]
        return [self.idx_to_token[index] for index in indices]

    @property
    def unk(self):  # Index for the unknown token
        return 0

    @property
    def token_freqs(self):  # Index for the unknown token
        return self._token_freqs

def load_data_nmt(batch_size, num_steps, device, num_examples=600):
    text = preprocess_nmt(read_data_nmt())
    source, target = tokenize_nmt(text, num_examples)
    src_vocab = Vocab(source, min_freq=2,
                          reserved_tokens=['<pad>', '<bos>', '<eos>'])
    tgt_vocab = Vocab(target, min_freq=2,
                          reserved_tokens=['<pad>', '<bos>', '<eos>'])
    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)
    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)

    # # ğŸ‘‡ åœ¨è¿™é‡Œå°†æ‰€æœ‰å¼ é‡è½¬ç§»åˆ°ç›®æ ‡è®¾å¤‡
    # src_array = src_array.to(device)
    # src_valid_len = src_valid_len.to(device)
    # tgt_array = tgt_array.to(device)
    # tgt_valid_len = tgt_valid_len.to(device)

    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)
    data_iter = load_array(data_arrays, batch_size)
    return data_iter, src_vocab, tgt_vocab

def load_array(data_arrays, batch_size, is_train=True):
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

def preprocess_nmt(text):
    def no_space(char, prev_char):
        return char in set(',.!?') and prev_char != ' '

    # Replace non-breaking space with space, and convert uppercase letters to
    # lowercase ones
    text = text.replace('\u202f', ' ').replace('\xa0', ' ').lower()
    # Insert space between words and punctuation marks
    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char
           for i, char in enumerate(text)]
    return ''.join(out)

def tokenize_nmt(text, num_examples=None):
    source, target = [], []
    for i, line in enumerate(text.split('\n')):
        if num_examples and i > num_examples:
            break
        parts = line.split('\t')
        if len(parts) == 2:
            source.append(parts[0].split(' '))
            target.append(parts[1].split(' '))
    return source, target

def truncate_pad(line, num_steps, padding_token):
    if len(line) > num_steps:
        return line[:num_steps]  # Truncate
    return line + [padding_token] * (num_steps - len(line))  # Pad


def grad_clipping(net, theta):
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))
    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm

def build_array_nmt(lines, vocab, num_steps):
    lines = [vocab[l] for l in lines]
    lines = [l + [vocab['<eos>']] for l in lines]
    array = torch.tensor([truncate_pad(
        l, num_steps, vocab['<pad>']) for l in lines])
    valid_len = reduce_sum(
        astype(array != vocab['<pad>'], torch.int32), 1)
    return array, valid_len

def read_data_nmt():
    data_dir = download_extract('fra-eng')
    with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding='utf-8') as f:
        return f.read()

def download_extract(name, folder=None):
    fname = download(name)
    base_dir = os.path.dirname(fname)
    data_dir, ext = os.path.splitext(fname)
    if ext == '.zip':
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('.tar', '.gz'):
        fp = tarfile.open(fname, 'r')
    else:
        assert False, 'Only zip/tar files can be extracted.'
    fp.extractall(base_dir)
    return os.path.join(base_dir, folder) if folder else data_dir

def download(name, cache_dir=os.path.join('..', 'data')):
    """Download a file inserted into DATA_HUB, return the local filename.

    Defined in :numref:`sec_kaggle_house`"""
    assert name in DATA_HUB, f"{name} does not exist in {DATA_HUB}."
    url, sha1_hash = DATA_HUB[name]
    os.makedirs(cache_dir, exist_ok=True)
    fname = os.path.join(cache_dir, url.split('/')[-1])
    if os.path.exists(fname):
        sha1 = hashlib.sha1()
        with open(fname, 'rb') as f:
            while True:
                data = f.read(1048576)
                if not data:
                    break
                sha1.update(data)
        if sha1.hexdigest() == sha1_hash:
            return fname  # Hit cache
    print(f'Downloading {fname} from {url}...')
    r = requests.get(url, stream=True, verify=True)
    with open(fname, 'wb') as f:
        f.write(r.content)
    return fname


class Timer:
    """Record multiple running times."""
    def __init__(self):
        """Defined in :numref:`subsec_linear_model`"""
        self.times = []
        self.start()

    def start(self):
        """Start the timer."""
        self.tik = time.time()

    def stop(self):
        """Stop the timer and record the time in a list."""
        self.times.append(time.time() - self.tik)
        return self.times[-1]

    def avg(self):
        """Return the average time."""
        return sum(self.times) / len(self.times)

    def sum(self):
        """Return the sum of time."""
        return sum(self.times)

    def cumsum(self):
        """Return the accumulated time."""
        return np.array(self.times).cumsum().tolist()

class Accumulator:
    def __init__(self, n):
        """Defined in :numref:`sec_softmax_scratch`"""
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

ones = torch.ones
zeros = torch.zeros
tensor = torch.tensor
arange = torch.arange
meshgrid = torch.meshgrid
sin = torch.sin
sinh = torch.sinh
cos = torch.cos
cosh = torch.cosh
tanh = torch.tanh
linspace = torch.linspace
exp = torch.exp
log = torch.log
normal = torch.normal
rand = torch.rand
matmul = torch.matmul
int32 = torch.int32
float32 = torch.float32
concat = torch.cat
stack = torch.stack
abs = torch.abs
eye = torch.eye
numpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)
size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)
reshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)
to = lambda x, *args, **kwargs: x.to(*args, **kwargs)
reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)
argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)
astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)
transpose = lambda x, *args, **kwargs: x.t(*args, **kwargs)


if __name__ == '__main__':
    main()